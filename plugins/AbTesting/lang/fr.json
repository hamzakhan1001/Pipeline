{
    "AbTesting": {
        "1DayAnd1Hour": "1 jour et 1 heure",
        "1DayAndYHours": "1 jour et %1$s heures",
        "1Hour": "1 heure",
        "AbTesting": "Test A/B",
        "ActionArchiveExperiment": "Archiver le test A/B",
        "ActionArchiveExperimentSuccess": "Le test A/B a été archivé avec succès",
        "ActionEditExperimentAnyway": "Modifier tout de même le test A/B",
        "ActionFinishExperiment": "Terminer le test A/B",
        "ActionViewReport": "Voir le rapport",
        "ActivateExperimentOnAllPages": "Les visiteurs participent à ce test A/B lorsqu'ils entrent depuis n'importe quelle page",
        "ActiveExperimentOnSomePages": "Les visiteurs entrent dans ce test A/B lorsque l'URL est égale à",
        "ArchiveReportConfirm": "Êtes-vous sûr de vouloir archiver ce test A/B ? Le test A/B n'apparaîtra plus dans les rapports et ne pourra pas être utilisé pour la segmentation une fois qu'il aura été archivé.",
        "ArchiveReportInfo": "Archiver le test A/B. Lorsque vous archivez le test A/B, il ne sera pas supprimé mais le test A/B ne sera plus disponible dans l'interface graphique de Matomo ou pour la segmentation.",
        "AverageX": "Moyenne %1$s",
        "ChooseExperiment": "Choisir un test A/B",
        "ClickToCreateNewGoal": "Cliquez ici pour créer un nouvel objectif si une métrique de réussite est absente de la liste.",
        "ColumnBounceRateDocumentation": "Le pourcentage de visites qui n'ont eu qu'une seule page vue. Cela signifie que le visiteur a quitté la page cible directement après être entré dans le test A/B.",
        "ColumnBouncesDocumentation": "Le nombre de visites qui ont commencé et qui se sont terminées lorsqu'elles sont entrées dans une page cible de test A/B. Cela signifie que le visiteur est parti après avoir consulté uniquement une page cible.",
        "ColumnConversionsPerVisit": "Conversions par visite",
        "ColumnDetectedEffect": "Effet détecté",
        "ColumnDetectedEffectDocumentation": "Le pourcentage de variation comparé à la version originale. Un effet détecté positif signifie que la variation est plus performante que la version originale, tandis qu'un effet détecté négatif signifie que la variation est moins performante que la version originale.",
        "ColumnOrdersPerVisit": "Commandes par visite",
        "ColumnOrdersRevenuePerVisit": "Revenue par visite (depuis les commandes)",
        "ColumnRemainingVisitors": "Visteurs restants",
        "ColumnRemainingVisitorsDocumentation": "Le nombre de visiteurs uniques supplémentaires nécessaires pour participer au test A/B afin de pouvoir tirer des résultats concluants.",
        "ColumnRevenuePerVisit": "Revenue par visite",
        "ColumnSignificanceRate": "Importance statistique",
        "ColumnSignificanceRateDocumentation": "Plus le pourcentage de signification statistique est élevé, plus il est probable que l'effet détecté soit réel, reproductible et non dû au hasard.",
        "ColumnTimeOnSite": "Temps passé sur le site",
        "ColumnTotalConversions": "Conversions totales",
        "ColumnTotalConversionsPerVisit": "Conversions par visite",
        "ColumnTotalRevenue": "Revenu total",
        "ColumnTotalRevenuePerVisit": "Revenue par visite",
        "ColumnUniqueVisitorsDocumentation": "Le nombre de visiteurs uniques qui ont participé à votre test A/B.",
        "ColumnVisitsDocumentation": "Le nombre de visites que votre test A/B a reçues. Toutes les visites d'un visiteur qui est entré une fois dans le test A/B comptent pour cette métrique visites. Par conséquent, ce nombre est généralement plus élevé que le nombre de \"visites entrées actives\".",
        "ColumnVisitsEnteredDocumentation": "Le nombre de visites où un visiteur est entré dans une page cible de ce test A/B.",
        "ConclusionLosingVariation": "Il existe une variante dont les performances sont nettement inférieures à celles de la version originale.",
        "ConclusionNoConclusion": "Pour tirer des résultats concluants, une variation doit n'avoir aucun visiteur restant et être statistiquement significative.",
        "ConclusionNoVariationHasEnoughVisitors": "D'autres visiteurs sont nécessaires pour tirer des résultats concluants.",
        "ConclusionNoVariationIsSignificant": "Aucune variation n'est actuellement suffisamment significative pour tirer des résultats concluants.",
        "ConclusionNoVariationRecordedYet": "Aucune activité de test A/B n'a encore été enregistrée pour une quelconque variation. Il semble qu'aucun visiteur ne soit entré dans le test A/B. Peut-être que le code du test A/B doit être intégré dans votre projet.",
        "ConclusionSignificantVariation": "Il existe une variation dont les performances sont nettement supérieures à celles de la version originale, mais elle n'a pas atteint l'effet minimal détectable (EMD) attendu de %1$s.",
        "ConclusionWinningVariation": "Il existe une variante dont les performances sont nettement supérieures à celles de la version originale et qui a atteint l'effet minimal détectable (EMD) attendu de %1$s.",
        "ConfidenceThreshold": "Seuil de fiabilité",
        "ConfirmFinishExperiment": "Êtes-vous sûr de vouloir terminer ce test A/B maintenant ? Il ne sera pas possible de recommencer ce test A/B une fois qu'il sera terminé. N'oubliez pas de supprimer le code de cet test A/B de votre projet afin que vos visiteurs ne puissent plus entrer dans le test.",
        "ConfirmUpdateStartsExperiment": "La date de début prévue est passée, ce qui signifie que le test A/B va commencer immédiatement. Êtes-vous sûr de vouloir lancer ce test A/B ? Nous recommandons de ne pas modifier un test A/B une fois qu'il a été lancé, car cela pourrait entraîner des erreurs d'interprétation des résultats.",
        "CreateNewExperiment": "Créer un nouveau test A/B",
        "CreateNewExperimentNow": "Créer un nouveau test A/B maintenant",
        "CurrentTimeInUTC": "L'heure actuelle en format UTC est",
        "Definition": "Définition",
        "DeleteExperimentConfirm": "Êtes-vous sûr de vouloir supprimer ce test A/B ? Une fois qu'un test A/B a été supprimé, il ne sera pas possible de le restaurer.",
        "DeleteExperimentInfo": "Supprimer le test A/B. Il ne sera pas possible de restaurer ce test A/B par la suite.",
        "EcommerceOrders": "Commandes Ecommerce",
        "EcommerceOrdersRevenue": "Revenue des commandes Ecommerce",
        "EditExperiment": "Modifier le test A/B %s",
        "EditThisExperiment": "Modifier le test A/B",
        "EmbedCode": "Code à intégrer",
        "EqualsDateInYourTimezone": "Cela correspond à la date suivante dans votre fuseau horaire :",
        "ErrorArrayMissingKey": "Clé de tableau manquante \"%1$s\" dans \"%2$s\" à la position \"%3$s\".",
        "ErrorArrayMissingValue": "Valeur manquante pour la clé du tableau \"%1$s\" dans \"%2$s\" à la position \"%3$s\".",
        "ErrorCreateNoUrlDefined": "Veuillez entrer une URL pour définir sur quelles pages le test A/B doit être activé.",
        "ErrorExperimentAlreadyStarted": "Le test A/B ne peut pas être lancé car il a déjà été commencé.",
        "ErrorExperimentCannotBeFinished": "Ce test A/B ne peut pas être terminé car il l'a déjà été.",
        "ErrorExperimentCannotBeUpdatedBecauseArchived": "Ce test A/B ne peut pas être mis à jour car il a été archivé.",
        "ErrorExperimentDoesNotExist": "Le test A/B demandé n'existe pas",
        "ErrorExperimentNameIsAlreadyInUse": "Le nom du test A/B est déjà utilisé par un autre test A/B.",
        "ErrorInnerIsNotAnArray": "Chaque \"%1$s\" dans \"%2$s\" doit être un tableau.",
        "ErrorInvalidRegExp": "L'expression régulière \"%1$s\" n'a pas un format valide.",
        "ErrorInvalidValue": "Valeur non valide pour \"%1$s\" fournie (\"%2$s\").",
        "ErrorNotAnArray": "\"%1$s\" doit être un tableau.",
        "ErrorNotEnabledForExperiment": "Le \"%1$s\" donné n'est pas activé pour ce test A/B.",
        "ErrorNotValidUrl": "%1$s n'est pas une URL valide. Assurez-vous qu'elle commence par exemple par http://",
        "ErrorVariationAllocatedNot100Traffic": "Vous avez alloué plus de 100%% à toutes les variations. Veuillez réduire le pourcentage de trafic alloué à vos variantes afin que le total soit de 100%%.",
        "ErrorVariationAllocatedNotEnoughOriginal": "Nous avons détecté que la version originale reçoit beaucoup moins de trafic que ce qu'elle devrait recevoir par défaut. Nous recommandons d'augmenter le trafic alloué à la version originale en diminuant le pourcentage alloué aux autres variantes.",
        "ErrorVariationNameOriginalNotAllowed": "Le nom de variation \"Original\" est un nom de variation réservé et ne peut être utilisé.",
        "ErrorXContainsOnlyNumbers": "Le \"%1$s\" ne doit pas contenir uniquement des chiffres, veuillez utiliser au moins une lettre.",
        "ErrorXContainsWhitespace": "Le \"%1$s\" ne doit pas contenir d'espace.",
        "ErrorXLaterThanY": "\"%1$s\" est postérieur à \"%2$s\".",
        "ErrorXLaterThanYButEqual": "\"%1$s\" doit être postérieur à \"%2$s\" mais ils sont égaux.",
        "ErrorXNotANumber": "\"%1$s\" doit être un nombre.",
        "ErrorXNotInFuture": "\"%1$s\" doit être dans le futur.",
        "ErrorXNotProvided": "Veuillez indiquer une valeur pour \"%1$s\".",
        "ErrorXNotWhitelisted": "La valeur pour \"%1$s\" n'est pas autorisée, utilisez une de celles-ci : %2$s.",
        "ErrorXOnlyAlNumDash": "Les caractères spéciaux pour \"%1$s\" ne sont pas autorisés.",
        "ErrorXTooHigh": "\"%1$s\" est trop élevé, la valeur maximale autorisée est %2$s.",
        "ErrorXTooLong": "\"%1$s\" est trop long, %2$s caractères maximum sont autorisés.",
        "ErrorXTooLow": "\"%1$s\" est trop faible, la valeur minimale autorisée est %2$s.",
        "ExcludedTargets": "Cibles exclues",
        "ExpectedImprovement": "Effet minimal détectable attendu",
        "Experiment": "Test A/B",
        "ExperimentCreated": "Le test A/B a été créé avec succès. Vous pouvez maintenant le configurer davantage. Nous vous recommandons de jeter un coup d'œil à \"Métriques à succès\".",
        "ExperimentCreatedInfo1": "Le test A/B doit commencer le",
        "ExperimentCreatedInfo2": "et fonctionnera jusqu'à ce que",
        "ExperimentCreatedInfo3": "Veillez à effectuer tous les changements nécessaires avant le début du test A/B, car il n'est pas recommandé de modifier le test A/B une fois qu'il a été lancé.",
        "ExperimentFinished": "Le test A/B s'est terminé avec succès.",
        "ExperimentFinishedInfo1": "Ce test A/B est terminé. Nous recommandons de ne pas apporter de modifications à un test A/B terminé, car cela pourrait entraîner des interprétations erronées des résultats.",
        "ExperimentFinishedInfo2": "Veillez à supprimer de votre site Web, de votre application ou de votre serveur tout code intégré à ce test A/B.",
        "ExperimentIsFinishedPleaseRemoveCode": "Une fois le test A/B terminé, assurez-vous de supprimer de votre site Web, de votre application ou de votre serveur tout code intégré à ce test A/B.",
        "ExperimentName": "Nom du test A/B",
        "ExperimentOverview": "Vue d'ensemble du test A/B",
        "ExperimentReportPreview": "Voici un exemple de rapport qui s'affiche une fois qu'un test A/B a été lancé.",
        "ExperimentRequiresUpdateBeforeViewEmbedCode": "Vous avez des modifications non sauvegardées pour ce test A/B. Veuillez enregistrer ou annuler vos modifications pour afficher le code à intégrer.",
        "ExperimentRunningInfo1": "Ce test A/B a été lancé le",
        "ExperimentRunningInfo2": "et devrait se terminer le",
        "ExperimentRunningInfo3": "Nous recommandons de ne pas apporter de modifications à un test A/B en cours, car cela pourrait entraîner des interprétations erronées des résultats.",
        "ExperimentStarted": "Le test A/B a été lancé avec succès.",
        "ExperimentUpdated": "Le test A/B a été mis à jour avec succès.",
        "ExperimentWillStartFromFirstTrackingRequest": "Ce test A/B démarrera automatiquement dès qu'il sera intégré à votre projet, à moins que vous n'ayez configuré une date programmée. Veillez à effectuer toutes les configurations nécessaires à l'avance car il n'est pas recommandé de modifier un test A/B une fois qu'il a été lancé.",
        "Experiments": "Tests A/B",
        "ExperimentsOverviewSubcategoryHelp": "Un test A/B vous permet de comparer différentes versions et de voir quelle variation a le plus de succès. Vous trouverez ici un aperçu de tous les tests actifs et des taux de conversion associés.",
        "FieldConfidenceThresholdHelp": "L'objectif d'un test A/B est de s'assurer que vous recueillez suffisamment de données pour apporter des changements en toute confiance sur la base des résultats de ce test. Plus le nombre est élevé, plus il est probable que les résultats sont réels, reproductibles et non dus au hasard.",
        "FieldDescriptionHelp": "Ce champ est utilisé pour décrire les éléments qui seront comparés. Par exemple, \"Comparaison de la couleur du bouton bleu et rouge d'achat immédiat \".",
        "FieldDescriptionPlaceholder": "Par exemple : \"Comparaison de la couleur des boutons d'achat bleu et rouge\"",
        "FieldExcludedTargetsHelp": "En définissant des exclusions, vous pouvez limiter les pages sur lesquelles un visiteur n'entrera pas dans ce test A/B. Si une page correspond à l'une de ces conditions, le visiteur n'entrera pas dans ce test A/B.",
        "FieldExcludedTargetsLabel": "Un visiteur n'entrera pas dans le test A/B lorsque",
        "FieldExperimentNameHelp": "Le nom est un nom unique pour ce test A/B. Le nom choisi peut être visible par vos utilisateurs dans le code source ou l'URL lors de l'exécution du test A/B. Utilisez uniquement des caractères alphanumériques, sans espace ni caractères spéciaux. Maximum %1$s caractères sont autorisés.",
        "FieldHypothesisHelp": "L'hypothèse explique ce que vous prévoyez lorsqu'un test A/B sera réalisé, quel sera le résultat et pourquoi il se produira. Par exemple, \"%1$sSi%2$s je change la couleur du bouton Acheter maintenant, %3$salors%4$s j'espère vendre plus de produits %5$sparce que%6$s le bouton sera plus visible\". L'hypothèse est une étape importante dans la définition de votre test A/B et nous vous recommandons de prendre le temps d'y réfléchir.",
        "FieldHypothesisPlaceholder": "Par exemple : \"Si je change la couleur du bouton \"Acheter maintenant\", j'espère vendre plus de produits car le bouton sera plus visible.\"",
        "FieldIncludedTargetsHelp2": "Les cibles vous permettent de définir sur quelles pages un visiteur doit entrer dans ce test A/B. Vous pouvez définir une ou plusieurs conditions. Par exemple, vous pouvez définir l'exécution d'un test A/B lorsque l'URL ou le chemin d'accès est égal à une certaine valeur ou seulement si un certain paramètre d'URL est présent dans l'URL. Un visiteur entrera dans le test A/B lorsqu'une des conditions est remplie, et non si toutes les conditions sont remplies. Toutes les conditions seront évaluées sans tenir compte de la casse.",
        "FieldIncludedTargetsLabel": "Un visiteur entrera dans le test A/B lorsque",
        "FieldMinimumDetectableEffectHelp1": "L'effet minimum détectable est l'amélioration minimale relative que vous vous attendez à détecter. Par exemple, si le taux de conversion d'un objectif est actuellement de 10%%, et que vous attendez un EDM de 20%%, alors une variation devra avoir un taux de conversion d'au moins 12%% pour être une variation gagnante.",
        "FieldMinimumDetectableEffectHelp2": "Si vous vous attendez à un petit effet, nous vous recommandons de choisir 10 %%, pour un effet moyen, choisissez 40 %% et pour un effet important, choisissez 70 %%.",
        "FieldPercentageParticipantsHelp": "Indiquez combien de vos visiteurs doivent participer à ce test A/B. Si vous sélectionnez 70 %%, alors 70 %% de tous vos visiteurs participeront à ce test A/B et verront soit la version originale, soit une variation. Les 30 %% restants ne participeront pas au test A/B et verront toujours la version originale.",
        "FieldPercentageParticipantsLabel": "Pourcentage de visiteurs qui entrent dans ce test A/B",
        "FieldPercentageVariationsHelp": "Il est recommandé de montrer chaque variation à un nombre égal de visiteurs (par défaut) mais vous pouvez modifier le pourcentage pour chaque variation. La somme de toutes les variations, y compris la version originale, doit être de 100 %%. Assurez-vous qu'une partie du trafic est toujours allouée à la version originale.",
        "FieldPercentageVariationsLabel": "Pourcentage du trafic alloué à chaque variation",
        "FieldRedirectHelp1": "Si vous souhaitez rediriger vos utilisateurs vers une page différente lorsqu'ils participent à ce test A/B, vous pouvez éventuellement configurer une URL de redirection pour chaque variation. Ceci est utile lorsque vous exécutez un test A/B dans le navigateur en utilisant notre modèle JavaScript de test A/B. Si vous configurez une URL, le \"Code embarqué\" inclura automatiquement le code de suivi pour effectuer une redirection. Il vous suffit donc de copier/coller le code de suivi dans votre projet et le tour est joué.",
        "FieldRedirectHelp2": "Si les redirections ne doivent pas être exécutées sur toutes les pages, nous vous recommandons de veiller à spécifier sur quelles pages une redirection doit être exécutée sous \"Pages cibles\".",
        "FieldRedirectHelp3": "Avec notre %1$s modèle PHP de test A/B PHP %2$s, vous pouvez également rediriger les utilisateurs côté serveur dans votre projet PHP.",
        "FieldScheduleExperimentFinishHelp": "Laissez le champ vide si vous voulez terminer le test A/B manuellement. S'il est spécifié, ce test A/B se terminera automatiquement à la date de fin. Si vous programmez la fin automatique du test A/B, assurez-vous d'exécuter ce test A/B suffisamment longtemps pour que les résultats soient réels et non dus au hasard. La date spécifiée sera supposée être dans le fuseau horaire %1$sUTC%2$s.",
        "FieldScheduleExperimentFinishLabel": "Terminer le test A/B sur",
        "FieldScheduleExperimentStartHelp": "Laissez le champ vide si vous souhaitez démarrer le test A/B dès que ce test A/B est intégré à votre projet. Veillez à terminer la configuration de ce test A/B avant la date de démarrage prévue. Il n'est pas recommandé de modifier un test A/B une fois qu'il a été lancé, car cela pourrait entraîner des interprétations erronées des résultats. La date spécifiée sera supposée être dans le fuseau horaire %1$sUTC%2$s.",
        "FieldScheduleExperimentStartLabel": "Commencez le test A/B sur",
        "FieldSuccessConditionsHelp": "Nous utilisons l'effet minimum détectable et le seuil de confiance (statistique significative) pour calculer le nombre de visiteurs nécessaires avant que vous puissiez être sûr des résultats. Pendant la durée de vie d'un test A/B, vous pouvez voir de nombreux gagnants potentiels différents qui obtiennent l'effet désiré. Cependant, vous devez exécuter le test A/B suffisamment longtemps pour vous assurer que l'effet détecté n'est pas dû au hasard.",
        "FieldSuccessMetricsHelp1": "Les métrique de succès vous aident à évaluer laquelle des variations est la plus réussie et devrait être utilisée à l'avenir.",
        "FieldSuccessMetricsHelp2": "Vous pouvez sélectionner une ou plusieurs métriques pour valider votre hypothèse. Matomo affichera alors un rapport comparant les différentes variations pour chacun des paramètres choisis.",
        "FieldSuccessMetricsHelp3": "Nous vous recommandons de ne pas modifier les paramètres de réussite que vous avez sélectionnés une fois qu'un test A/B a été lancé, car cela pourrait entraîner des interprétations erronées des résultats.",
        "FieldSuccessMetricsLabel": "Sélectionnez une ou plusieurs métrique de réussite",
        "FieldVariationsHelp": "Le terme variations désigne toute nouvelle version (variation) que vous allez tester par rapport à la version originale (actuelle). Par exemple, si vous souhaitez tester différentes couleurs de boutons les unes par rapport aux autres, créez une variation pour chaque couleur que vous souhaitez comparer. Les noms des variations peuvent être visibles pour vos utilisateurs dans le code source ou l'URL. Utilisez uniquement des caractères alphanumériques, sans espace ni caractères spéciaux. Le nom d'une variation peut comporter jusqu'à 50 caractères.",
        "FilesystemDirectory": "répertoire",
        "Filter": "Filtre",
        "FinishDate": "Date de fin",
        "FormCreateExperimentIntro": "Un test A/B vous permet de comparer différentes versions et de voir laquelle est la plus performante. Ces champs sont obligatoires pour créer un test A/B. Une fois le test A/B créé, vous pourrez le personnaliser davantage.",
        "FormScheduleIntroduction": "Par défaut, un test A/B démarre dès qu'il est intégré à votre projet et se termine dès que vous le terminez manuellement. Vous pouvez également programmer une date de début et de fin pour ce test A/B.",
        "GettingStarted": "Premiers pas",
        "HowToGetStartedAdminAccess": "Vous pouvez %1$scréer un nouveau test A/B maintenant%2$s.",
        "HowToGetStartedUserAccess": "Veuillez demander à un utilisateur ayant un accès en écriture de créer un nouveau test A/B dans le menu \"Administration\".",
        "Hypothesis": "Hypothèse",
        "IncludedTargets": "Cibles incluses",
        "Manage": "Gérer",
        "ManageExperiments": "Gérer les tests A/B",
        "ManageExperimentsIntroduction": "Un test A/B vous permet de comparer différentes versions et de voir quelle variation vous donne le plus de succès. Les tests A/B sont également connus sous le nom d'expériences ou de tests fractionnés. Dans un test A/B, vous montrez deux ou plusieurs variantes à vos visiteurs et la variante la plus performante l'emporte. Lorsqu'un visiteur entre dans le test A/B, une variation est choisie au hasard et le visiteur verra cette variation pour toutes les visites suivantes. En expérimentant de cette manière, vous maximisez vos chances de succès.",
        "ManageExperimentsSubcategoryHelp": "Un test A/B vous permet de comparer différentes versions et de voir laquelle est la plus performante. Cette section vous permet de créer et de gérer des tests A/B pour votre site.",
        "MenuTitleExperiment": "Test A/B \"%1$s\"",
        "MinimumDetectableEffectMDE": "Effet minimal détectable (EMD)",
        "NExperiments": "%s tests A/B",
        "NameOriginalVariation": "Version originale",
        "NavigationBack": "Retour",
        "NeedHelp": "Besoin d'aide ?",
        "NewExperimentTargetPageHelp": "Par défaut, un test A/B sera exécuté sur toutes vos pages. Alternativement, vous pouvez choisir d'exécuter le test A/B seulement sur une page spécifique. Si vous spécifiez un domaine incluant un chemin d'accès facultatif, le test A/B ne sera exécuté que sur cette page. Une fois que le test A/B a été créé, vous pouvez inclure et exclure d'autres pages.",
        "NoActiveExperiment": "Il n'y a pas de test A/B en cours ou terminé.",
        "NoActiveExperimentConfigured": "Il n'y a pas de test A/B actif.",
        "NoExperimentsFound": "Il n'y a pas de tests A/B avec ce statut.",
        "PercentageParticipants": "Pourcentage de participants",
        "PluginDescription": "Extension Test A/B",
        "Preview": "Rapport d'échantillonnage",
        "Redirects": "Redirections",
        "RelatedActions": "À partir de là, vous pouvez effectuer l'une des actions suivantes",
        "ReportDateCannotBeChanged": "La date d'un rapport de test A/B ne peut pas être modifiée",
        "ReportStatusFinished": "Le test A/B est terminé. Il a été réalisé pour %1$s de %2$s à %3$s.",
        "ReportStatusRunning": "Le test A/B est en cours pour %1$s depuis %2$s.",
        "ReportWhenToDeclareWinner": "Quand désignerr un gagnant ? Ce rapport de test A/B peut indiquer une variation gagnante ou perdante, mais il est essentiel d'effectuer des tests A/B pendant au moins un ou deux cycles d'affaires complets. Comme le comportement des utilisateurs varie selon les heures et les jours de la semaine, nous recommandons d'effectuer des tests A/B pendant des jours entiers ou, mieux encore, des semaines entières, afin de s'assurer que l'effet détecté n'est pas dû au hasard.",
        "Rule": "Règle",
        "RunExperimentWithEmailCampaign": "Exécution d'un test A/B dans une campagne (ex. campagnes publicitaires, campagnes d'emailing)",
        "RunExperimentWithJsClient": "Exécution d'un test A/B dans le navigateur avec le code de suivi JavaScript Matomo",
        "RunExperimentWithJsTracker": "Exécution d'un test A/B pour un site web sur le serveur",
        "RunExperimentWithOtherSDK": "Exécuter un test A/B dans une application sur iOS, Android, PHP, Java, C#, Python, …",
        "Schedule": "Planification",
        "StartDate": "Date de début",
        "Status": "Statut",
        "StatusActive": "Actif",
        "StatusArchived": "Archivé",
        "StatusCreated": "Créé",
        "StatusFinished": "Terminé",
        "StatusRunning": "En cours d'exécution",
        "SuccessConditions": "Conditions de succès",
        "SuccessMetric": "Métrique de succès",
        "SuccessMetricDetails": "Détail de la métrique de succès",
        "SuccessMetrics": "Métriques de succès",
        "Target": "Cible",
        "TargetAttributePath": "Chemin",
        "TargetAttributeUrl": "URL",
        "TargetAttributeUrlParameter": "Paramètre d'URL",
        "TargetAttributeUrlParameterExample": "nameOfUrlParameter",
        "TargetComparisionsCaseInsensitive": "Toutes les comparaisons sont évaluées sans tenir compte de la casse.",
        "TargetComparisons": "Comparaisons",
        "TargetPageTestErrorInvalidUrl": "Entrez une URL incluant un protocole.",
        "TargetPageTestLabel": "Entrez une URL complète, y compris le protocole, pour vérifier si un visiteur entre dans le test A/B sur cette URL :",
        "TargetPageTestTitle": "Valideur d'URL",
        "TargetPageTestUrlMatches": "Un visiteur va entrer dans ce test A/B pour cette URL",
        "TargetPageTestUrlNotMatches": "Un visiteur n'entrera pas dans ce test A/B pour cette URL",
        "TargetPages": "Pages ciblées",
        "TargetTypeContains": "contient",
        "TargetTypeEqualsExactly": "strictement égal",
        "TargetTypeEqualsExactlyInfo": "La valeur doit correspondre exactement, y compris le protocole URL, la requête de recherche et le hachage.",
        "TargetTypeEqualsSimple": "est égal",
        "TargetTypeEqualsSimpleInfo": "L'URL correspondra à n'importe quel protocole (par exemple http et https) avec ou sans le sous-domaine \"www.\". Tout slash de fin de chemin ainsi que la requête de recherche et la partie hashage de l'URL seront ignorés lors de la recherche de l'URL.",
        "TargetTypeExists": "existe",
        "TargetTypeIsAny": "n'importe quel",
        "TargetTypeIsNot": "n'est pas %s",
        "TargetTypeRegExp": "correspond à l'expression régulière",
        "TargetTypeRegExpInfo": "Toute expression régulière, par exemple \"^(.*)test(.*)$\".",
        "TargetTypeStartsWith": "commence par",
        "TrafficAllocation": "Répartition du trafic",
        "UniqueVisitorsActivelyEntered": "Visiteurs uniques actifs entrés",
        "UpdatingData": "Mise à jour des données…",
        "UrlParameterValueToMatchPlaceholder": "Valeur à faire correspondre au nom du paramètre de l'URL",
        "Variation": "Variation",
        "VariationName": "Nom de la variation",
        "VariationPercentage": "Pourcentage de variation",
        "VariationRedirectUrl": "Variation de l'URL",
        "Variations": "Variations",
        "ViewReportInfo": "Voir le rapport de ce test A/B.",
        "VisitEnteredExperiment": "Visites entrées dans le test A/B",
        "VisitorEnteredNExperiments": "Visiteur entré dans les tests A/B %1$s",
        "VisitorEnteredOneExperiment": "Visiteur entré dans un test A/B",
        "VisitsActivelyEntered": "Visites actives entrées",
        "XDaysAnd1Hour": "%1$s jours et 1 heure",
        "XDaysAndYHours": "%1$s jours et %2$s heures",
        "Xhours": "%1$s heures"
    }
}
